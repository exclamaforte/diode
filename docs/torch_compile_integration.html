

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Accelerating torch.compile with Diode &mdash; diode 0.0.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=d45e8c67"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="_static/copybutton.js?v=f281be69"></script>
      <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Getting Started with Training Models with Diode" href="getting_started.html" />
    <link rel="prev" title="Welcome to Diode’s documentation!" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #2980B9" >

          
          
          <a href="index.html" class="icon icon-home">
            diode
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Accelerating torch.compile with Diode</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="#quick-start">Quick Start</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#step-1-install-torch-diode-models">Step 1: Install torch-diode-models</a></li>
<li class="toctree-l3"><a class="reference internal" href="#step-2-import-and-auto-register">Step 2: Import and Auto-Register</a></li>
<li class="toctree-l3"><a class="reference internal" href="#step-3-enable-fast-autotuning">Step 3: Enable Fast Autotuning</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#complete-example">Complete Example</a></li>
<li class="toctree-l2"><a class="reference internal" href="#benefits">Benefits</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#performance-improvements">Performance Improvements</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#advanced-configuration">Advanced Configuration</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#hardware-detection">Hardware Detection</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#integration-with-existing-workflows">Integration with Existing Workflows</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#training-workflows">Training Workflows</a></li>
<li class="toctree-l3"><a class="reference internal" href="#inference-workflows">Inference Workflows</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#supported-operations">Supported Operations</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="getting_started.html">Getting Started with Training Models with Diode</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/modules.html">API Documentation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Articles:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="articles/readme.html">Project Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="articles/readme.html#torch-diode">torch-diode</a></li>
<li class="toctree-l1"><a class="reference internal" href="articles/contributing.html">Contributing Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="articles/contributing.html#contributing-to-diode">Contributing to Diode</a></li>
<li class="toctree-l1"><a class="reference internal" href="articles/contributing.html#testing-and-code-coverage">Testing and Code Coverage</a></li>
<li class="toctree-l1"><a class="reference internal" href="articles/packaging.html">Packaging Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="articles/packaging.html#diode-packaging-setup">Diode Packaging Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="articles/workflows.html">Workflows Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="articles/workflows.html#matrix-multiplication-toolkit">Matrix Multiplication Toolkit</a></li>
<li class="toctree-l1"><a class="reference internal" href="articles/systems_architecture.html">Systems Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="articles/systems_architecture.html#torch-diode-systems-architecture">Torch-Diode Systems Architecture</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reference:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="genindex.html">Index</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: #2980B9" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">diode</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Accelerating torch.compile with Diode</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/torch_compile_integration.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="accelerating-torch-compile-with-diode">
<h1>Accelerating torch.compile with Diode<a class="headerlink" href="#accelerating-torch-compile-with-diode" title="Link to this heading"></a></h1>
<p>Diode can speeds up PyTorch’s <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code> by providing pre-trained models that predict optimal matrix multiplication configurations, eliminating the need for expensive runtime autotuning. This integration allows you to get the performance benefits of extensive autotuning with minimal compilation time.</p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Link to this heading"></a></h2>
<p>When PyTorch compiles matrix multiplication operations, it typically needs to search through many different kernel configurations to find the optimal one for your specific hardware and problem size. This process, called autotuning, can take substantial time during compilation.</p>
<p>Diode solves this by providing a pre-trained model that predicts the optimal configuration for a given hardware and problem size. This saves compilation time by eliminating the need for runtime autotuning, while still providing optimal performance.</p>
</section>
<section id="quick-start">
<h2>Quick Start<a class="headerlink" href="#quick-start" title="Link to this heading"></a></h2>
<p>Getting started with Diode acceleration is simple and requires only three steps:</p>
<section id="step-1-install-torch-diode-models">
<h3>Step 1: Install torch-diode-models<a class="headerlink" href="#step-1-install-torch-diode-models" title="Link to this heading"></a></h3>
<p>Install the pre-trained models package:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>torch-diode
</pre></div>
</div>
<p>This package contains pre-trained models for popular hardware configurations including NVIDIA H100 and AMD MI300X GPUs.</p>
</section>
<section id="step-2-import-and-auto-register">
<h3>Step 2: Import and Auto-Register<a class="headerlink" href="#step-2-import-and-auto-register" title="Link to this heading"></a></h3>
<p>Simply import the package to automatically register the best model for your hardware:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch_diode_models</span>
</pre></div>
</div>
<p>This import automatically:</p>
<ul class="simple">
<li><p>Detects your hardware configuration</p></li>
<li><p>Selects the most appropriate pre-trained model</p></li>
<li><p>Registers the model with PyTorch’s compilation system</p></li>
<li><p>Configures the prediction interface</p></li>
</ul>
</section>
<section id="step-3-enable-fast-autotuning">
<h3>Step 3: Enable Fast Autotuning<a class="headerlink" href="#step-3-enable-fast-autotuning" title="Link to this heading"></a></h3>
<p>Configure PyTorch to use Diode’s fast autotuning:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch._inductor</span><span class="w"> </span><span class="kn">import</span> <span class="n">config</span>

<span class="c1"># Enable fast autotuning with Diode models</span>
<span class="n">config</span><span class="o">.</span><span class="n">max_autotune</span> <span class="o">=</span> <span class="kc">True</span>
</pre></div>
</div>
</section>
</section>
<section id="complete-example">
<h2>Complete Example<a class="headerlink" href="#complete-example" title="Link to this heading"></a></h2>
<p>Here’s a complete example showing how to use Diode with torch.compile:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch_diode_models</span>  <span class="c1"># Auto-registers the best model for your hardware</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch._inductor</span><span class="w"> </span><span class="kn">import</span> <span class="n">config</span>

<span class="c1"># Configure PyTorch to use Diode acceleration</span>
<span class="n">config</span><span class="o">.</span><span class="n">max_autotune_gemm_backends</span> <span class="o">=</span> <span class="s2">&quot;DIODE&quot;</span>
<span class="n">config</span><span class="o">.</span><span class="n">max_autotune</span> <span class="o">=</span> <span class="kc">True</span>

<span class="c1"># Your existing PyTorch code - no changes needed!</span>
<span class="k">def</span><span class="w"> </span><span class="nf">matmul_function</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>

<span class="c1"># Compile with torch.compile - now accelerated by Diode</span>
<span class="n">compiled_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">matmul_function</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;max-autotune&quot;</span><span class="p">)</span>

<span class="c1"># Use as normal</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">2048</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2048</span><span class="p">,</span> <span class="mi">4096</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">compiled_fn</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="benefits">
<h2>Benefits<a class="headerlink" href="#benefits" title="Link to this heading"></a></h2>
<section id="performance-improvements">
<h3>Performance Improvements<a class="headerlink" href="#performance-improvements" title="Link to this heading"></a></h3>
<p>Diode provides significant improvements in both compilation time and runtime performance:</p>
<p><strong>Compilation Speed</strong>
* <strong>10x faster compilation</strong>: Eliminates expensive autotuning searches
* <strong>Instant predictions</strong>: Model inference takes microseconds vs. seconds of autotuning
* <strong>Consistent compile times</strong>: No variation based on problem size or hardware load</p>
<p><strong>Runtime Performance</strong>
* <strong>Max Autotune</strong>: We can match Max Autotune and Max Autotune EXHAUSTIVE performance.
Memory Efficiency
~~~~~~~~~~~~~~~~~</p>
<ul class="simple">
<li><p><strong>Reduced memory overhead</strong>: No need to store multiple kernel variants during compilation</p></li>
<li><p><strong>Predictable memory usage</strong>: Consistent memory consumption across different problem sizes</p></li>
</ul>
</section>
</section>
<section id="advanced-configuration">
<h2>Advanced Configuration<a class="headerlink" href="#advanced-configuration" title="Link to this heading"></a></h2>
<section id="hardware-detection">
<h3>Hardware Detection<a class="headerlink" href="#hardware-detection" title="Link to this heading"></a></h3>
<p>Diode automatically detects your hardware, but you can also specify it manually:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch_diode_models</span>

<span class="c1"># Check detected hardware</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Detected hardware: </span><span class="si">{</span><span class="n">torch_diode_models</span><span class="o">.</span><span class="n">get_detected_hardware</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># List available models</span>
<span class="n">available_models</span> <span class="o">=</span> <span class="n">torch_diode_models</span><span class="o">.</span><span class="n">list_available_models</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Available models: </span><span class="si">{</span><span class="n">available_models</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="integration-with-existing-workflows">
<h2>Integration with Existing Workflows<a class="headerlink" href="#integration-with-existing-workflows" title="Link to this heading"></a></h2>
<section id="training-workflows">
<h3>Training Workflows<a class="headerlink" href="#training-workflows" title="Link to this heading"></a></h3>
<p>Diode integrates seamlessly with existing training code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch_diode_models</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch._inductor</span><span class="w"> </span><span class="kn">import</span> <span class="n">config</span>

<span class="c1"># Enable Diode acceleration</span>
<span class="n">config</span><span class="o">.</span><span class="n">max_autotune</span> <span class="o">=</span> <span class="kc">True</span>

<span class="k">class</span><span class="w"> </span><span class="nc">MyModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">2048</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2048</span><span class="p">,</span> <span class="mi">1024</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">MyModel</span><span class="p">()</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

<span class="c1"># Compile with Diode acceleration</span>
<span class="n">compiled_model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;max-autotune&quot;</span><span class="p">)</span>

<span class="c1"># Training loop - faster compilation on first run</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
<span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">:</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">compiled_model</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>  <span class="c1"># Fast compilation + optimal performance</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="inference-workflows">
<h3>Inference Workflows<a class="headerlink" href="#inference-workflows" title="Link to this heading"></a></h3>
<p>Perfect for production inference where fast startup is critical:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch_diode_models</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch._inductor</span><span class="w"> </span><span class="kn">import</span> <span class="n">config</span>

<span class="c1"># Configure for inference</span>
<span class="n">config</span><span class="o">.</span><span class="n">max_autotune_gemm_backends</span> <span class="o">=</span> <span class="s2">&quot;DIODE&quot;</span>
<span class="n">config</span><span class="o">.</span><span class="n">fast_autotune</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">config</span><span class="o">.</span><span class="n">triton</span><span class="o">.</span><span class="n">cudagraphs</span> <span class="o">=</span> <span class="kc">True</span>  <span class="c1"># Enable CUDA graphs for even better performance</span>

<span class="c1"># Load your model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;my_model.pt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

<span class="c1"># Compile with minimal warmup time</span>
<span class="n">compiled_model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;max-autotune&quot;</span><span class="p">)</span>

<span class="c1"># First inference compiles quickly thanks to Diode</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">compiled_model</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="supported-operations">
<h2>Supported Operations<a class="headerlink" href="#supported-operations" title="Link to this heading"></a></h2>
<p>Diode currently accelerates the following matrix multiplication operations:</p>
<p><strong>Core Operations</strong>
* <code class="docutils literal notranslate"><span class="pre">torch.mm</span></code> - Basic matrix multiplication
* <code class="docutils literal notranslate"><span class="pre">torch.addmm</span></code> - Matrix multiplication with bias addition
* <code class="docutils literal notranslate"><span class="pre">torch.bmm</span></code> - Batch matrix multiplication</p>
<p><strong>Data Types</strong>
* <code class="docutils literal notranslate"><span class="pre">float16</span></code> (half precision)
* <code class="docutils literal notranslate"><span class="pre">bfloat16</span></code> (brain float)
* <code class="docutils literal notranslate"><span class="pre">float32</span></code> (single precision)</p>
<p><strong>Hardware Support</strong>
* NVIDIA GPUs: H100
* AMD GPUs: MI210</p>
<p>For more information on training custom models, see the <a class="reference internal" href="getting_started.html"><span class="doc">Getting Started with Training Models with Diode</span></a> guide.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="Welcome to Diode’s documentation!" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="getting_started.html" class="btn btn-neutral float-right" title="Getting Started with Training Models with Diode" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Author Name.
      <span class="lastupdated">Last updated on Sep 22, 2025.
      </span></p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>